\chapter{General introduction}\thumbforchapter
\newpage

\section{The central dogma of molecular biology}

The human body is formed by a collection of 37,000,000,000,000 cells\cite{Bianconi2013}, with each cell containing approximately 2 meters of DNA. This means that our bodies house an astounding 74,000,000,000 kilometers of DNA, which is equivalent to nearly 250 round trips to the sun! Our DNA is spread over 23 distinct structures called chromosomes and organized into roughly 20,000 genes. What makes all this even more intriguing is that all cells within our body possess exactly the same DNA, yet they exhibit remarkable diversity and specialization. How does a single set of instructions (DNA) give rise to such diverse cell types? What is the role of evolution in this process, and consequently, what are the differences in instructions between species? To better appreciate these fascinating phenomena, it is crucial to understand the central dogma of molecular biology (fig. \ref{fig:central_dogma}).

\begin{figure}[H]
    \includegraphics[width=\linewidth]{ch.introduction/imgs/central_dogma.png}
    \caption{\textbf{The central dogma of molecular biology.} DNA transcribes to RNA, and RNA translates to protein. Solid arrows indicate the general flow of information in the system, and dotted arrows are special cases.}
    \label{fig:central_dogma}
\end{figure}

The central dogma of molecular biology describes the flow of genetic information within a biological system. Whereas in a computer information is stored in bits, which can be either zero (0) or one (1), genetic information is stored in nucleotides, which can be either adenine (A), cytosine (C), guanine (G), or thymine (T). DNA is composed of two large strands of these four nucleotides that together form a double helix. Both strands contain the same information, but where there is a nucleotide A on one strand, there is always a corresponding nucleotide T on its complementary strand, and similarly for C and G. RNA, on the other hand, is a similar molecule but is typically single-stranded. It is transcribed from DNA and shares a similar nucleotide composition but replaces thymine (T) with uracil (U). RNA serves as the bridge between DNA and proteins. Through the process of translation, the information encoded in RNA is decoded and used to assemble chains of amino acids, known as proteins. Proteins carry out various tasks in our bodies, such as enabling chemical reactions, transporting other molecules, providing structure, and acting as regulators of DNA transcription and RNA translation.

Far from all the human DNA is transcribed to RNA, and not even all RNA translates to protein. As a general rule of thumb, we distinguish DNA sequences that get transcribed into RNA as genes. The human genome consists of approximately 20.000 protein-coding genes, and these genes equal only 1,5\% of the genome\cite{Piovesan2019}. Early molecular biologists mainly focused on protein-coding genes, thus the remaining 98.5\% of the DNA got known as ``junk DNA'', a controversial term in the field\cite{Graur2013}. We now know, however, that approximately 10\% of human DNA is functional\cite{Graur2013}, and around 80\% is involved in at least one biochemical process\cite{encode2012}. Almost all of the functional DNA that does not encode for protein is related to gene expression regulation.

\section{Gene expression regulation}

Even though a skin cell and a liver cell house identical DNA, they use completely different sets of genes. This is possible due to the tight regulation of gene expression, for which cells have a wide array of tools at their disposal. This thesis mainly focuses on transcription factors and their related chromatin context, which will be discussed in more detail.

\subsection{Transcription Factors}

A typical gene consists of its coding parts (exons), noncoding parts (introns), and the start signal (promoter). The promoter functions as a location where general transcription factors bind, which in turn recruit RNA polymerase II (RNAPII). RNAPII is the protein complex responsible for transcription, and is responsible for reading out the DNA gene and converting it to RNA.

The presence of general transcription factors and a promoter is generally enough for transcription, although on a low level\cite{Haberle2018}. Transcription regulation, and by extension gene expression regulation, occurs through transcription factors and enhancers (figure \ref{fig:TF}. Enhancers are regions on the DNA where transcription factors can bind. These transcription factors act like switches, determining whether the gene should be turned up or down in response to various signals and conditions.

Transcription factors bound to 

\begin{figure}[H]
    \center
    \includegraphics[width=0.65\linewidth]{ch.introduction/imgs/transcription_factor.png}
    \caption{Caption}
    \label{fig:TF}
\end{figure}

\subsection{Chromatin context}

To be able to fit two meters of DNA into each cell, the DNA needs to be carefully packaged. Chromatin refers to the complex of DNA, proteins, and RNA that makes up the genetic material within a cell's nucleus. It is like the packaging material for DNA, providing structural support and helping to organize the genetic material. The primary components of chromatin are DNA and histone proteins.

\begin{figure}[H]
    \center
    \includegraphics[width=0.65\linewidth]{ch.introduction/imgs/histones.png}
    \caption{Caption}
    \label{fig:histones}
\end{figure}

Histones are proteins around which DNA is tightly wrapped. DNA wraps around these histones like thread on a spool, forming a structure called a nucleosome. Nucleosomes are the basic units of chromatin.

The chromatin context plays a significant role in gene expression regulation. The DNA in chromatin is tightly wound around histones, which can either promote or inhibit gene expression. Here's how it works:

Histone Modifications: Chemical modifications, like acetylation, methylation, and phosphorylation, can occur on histones. These modifications can influence the structure of chromatin, making it more or less accessible to the cellular machinery that reads genes. For example, acetylation tends to open up the chromatin structure, allowing easier access to the genes and thus promoting their expression.

DNA Methylation: Another important aspect of gene regulation is DNA methylation, where methyl groups are added to certain regions of DNA. DNA methylation can cause genes to be "silenced" or turned off, as it prevents the cellular machinery from binding to the DNA and initiating gene transcription.

The way DNA is folded and packaged in the chromatin structure directly impacts how accessible different regions of DNA are to the cellular machinery responsible for transcription and gene expression. Regions of open chromatin are more accessible and likely to be actively transcribed, while tightly packed regions may be silenced.

\begin{figure}[H]
    \includegraphics[width=\linewidth]{ch.introduction/imgs/accessibility_horizontal.png}
    \caption{Caption}
    \label{fig:accessibility}
\end{figure}

\subsection{Other gene regulatory modes}

There are many other ways gene expression can be regulated. Examples are mRNA degradation regulation. Post-transcriptional modifications such as phosphorylation and symoylation. Signal transduction: cool example Michael Levin with flat worms.

% \subsubsection{mRNA degradation}
% \subsubsection{Post-transcriptional modification}
% \subsubsection{RNA transport}
% \subsubsection{Signal transduction}
Michael Levin is cool: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3841289/
sumoylation

\subsection{Gene regulatory networks}

Mapping how protein products of genes (e.g. transcription factors) influence the protein expression of other genes is crucial for understanding how cellular processes are regulated. A common abstraction to understand gene-gene interactions are gene regulatory networks.

The first concept of gene regulatory networks was proposed by Roy Britten and Eric Davidson in 1969\cite{Britten_1969}. They observed that a cell (i) responds to an external signal; (ii) then produces its own signal as a response; (iii) transmits its own signal to receptors that do not perceive the external signal; (iv) then responds to its own signal, and finally (v) produces a protein as a response. Without modern knowledge of gene regulation, they then predicted what the minimum requirements are for such a system. One of the things they then correctly predicted was the existence of transcription factors and promoter sequences. It took Eric Davidson more than 30 years to experimentally validate his original predictions\cite{Davidson_2002}.

Gene regulatory networks come in many forms and shapes, but are often modeled and visualized with direct gene-gene interactions (fig. \ref{fig:network}A). This means for instance that the protein product of gene $\alpha$ directly regulates the protein product of gene $\beta$, ignoring all steps in between. Even though this is a gross oversimplification of gene-gene interactions, these simple models can already exhibit complex behavior. One of the older and more well-known examples of complex behavior from a simple model is a Turing pattern, discovered by the famous computer scientist Alan Turing\cite{Turing1952}. This model consists of two genes, gene $\alpha$, and gene $\beta$, where gene $\alpha$ upregulates itself and gene $\beta$, but gene $\beta$ inhibits gene $\alpha$ (fig. \ref{fig:network}B). When modeling this simple two-gene network in a spatial setting it produces complex patterns (fig. \ref{fig:network}C), of which similar patterns have been observed in nature (fig. \ref{fig:network}D).

\begin{figure}[H]
    \includegraphics[width=\linewidth]{ch.introduction/imgs/network.png}
    \caption{\textbf{Basic gene regulatory networks.} (\textbf{A}) the standard schematic way of representing gene-gene interactions. Gene $\alpha$ upregulates gene $\beta$, and gene $\gamma$ downregulates gene $\delta$. (\textbf{B}) Gierer-Meinhardt gene regulatory network, where gene $\alpha$ upregulates itself and gene $\beta$, and gene $\beta$ downregulates gene $\alpha$. (\textbf{C}) Simulation of the Gierer-Meinhardt gene regulatory network in a spatial context. (\textbf{D}) A Mbuna pufferfish with Turing pattern. Turing pattern from: https://www.nature.com/articles/s43588-022-00306-0 and pufferfish photo taken by Tiia Monto: https://en.wikipedia.org/wiki/Mbu\_pufferfish\#/media/File:Tetraodon\_mbu\_2.jpg}
    \label{fig:network}
\end{figure}

Mapping the relations between genes is a hard problem and unfeasible to do by hand. Not only can potentially any gene have an (in)direct effect on any other gene, but the potential interactions also depend on the cell type. The 20.000 human protein-coding genes have 20.000$^2$=400.000.000 potential direct interactions, and if we consider indirect interactions, cell type-specific interactions, and combinatorial interactions the number of potential gene interactions explodes. To infer gene interactions at scale and make sense of the resulting networks we \textit{have} to make use of computational tools. The most common approach so far has been to measure RNA expression in a combination of settings and correlate the RNA expression of genes over these settings \cite{Zhang_2005,Margolin_2006}. Correlations above a certain threshold would indicate an (in)direct gene regulation. Adding more information to these networks, such as the chromatin state around genes\cite{Xu_2020,Kamal_2021}, improves the resulting networks. However, practically all gene regulatory network inference approaches compare cell states (e.g. liver vs skin), so the inferred gene networks are specific for these comparisons. In chapter \textit{TODO XYZ} we discuss the latest developments in grn inference.

\section{Genomics analysis}

A genomics project can be broken down into three main stages: wet lab work, dry lab work, and sequencing. The wet lab phase entails hands-on experimentation with physical materials like chemicals and biological samples. In contrast, the dry lab phase involves computationally interpreting and analyzing the data generated by the wet lab. The sequencing step falls between the wet lab and the dry lab. In this thesis, three different types of sequencing assays have been used and analyzed (ATAC-seq, ChIP-seq, and RNA-seq), and we'll briefly discuss their wet lab, sequencing, and dry lab parts. 

\subsection{wet lab}

Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) (CITE ATACSEQ) is a method to measure genome-wide accessibility. Accessible DNA is generally associated with active DNA, and vice versa. ATAC-seq works by adding a protein called tn5 transposase to a sample. This protein then proceeds to randomly cut up the genome. However, if a piece of DNA is inaccessible, for example, because a protein is bound or a histone modification is blocking access, the tn5 can not reach the DNA to cut it. Small DNA sequences thus represent accessible DNA as they could be cut. After treating DNA with tn5, one then isolates the small DNA fragments (+/- 1.000 base pairs long or less), which are then ready to be sequenced.

Chromatin ImmunoPrecipitation sequencing (ChIP) (CITE CHIPSEQ) is an assay to measure proteins in proximity to DNA. These proteins are generally transcription factors, but can also be histone modifications that make the DNA more or less permissive. It works by first fixating (gluing together) the chromatin (DNA and associated proteins) with formaldehyde. Afterward, you break the DNA into smaller pieces of for instance +/- 200 base pairs long. You then add proteins that bind to your protein of interest (antibodies) and filter out all the DNA sequences with bound antibodies. Filtering out the antibodies can be for instance done by magnets if magnetic antibodies were used or XYZ. As the final step, the DNA, proteins, and antibodies need to be separated, and the remaining DNA fragments can be sent for sequencing.

RNA-seq is a method to estimate which gene transcripts are present in a sample and in what quantity. The amount of RNA transcripts of a gene is used as a proxy for both the level of gene regulation as well as for the number of protein product that is present in a sample. RNA-seq works by first filtering out all the RNA in a sample, and then converting the RNA into DNA by reverse transcription (see fig. \ref{fig:central_dogma}. The resulting DNA then represents the number of gene transcripts for a gene were present, and can then be sequenced.

\subsection{Sequencing}

Sequencing is a lab technique used to determine the order of nucleotides of DNA. Many different techniques exist, but Illumina sequencing by synthesis is most common and ill explain. The first step in sequencing is the addition of adapters to the DNA. These adapters are bound to the beginning and end of the DNA strand. The DNA is then spread thinly over a surface, called the flow cell, where the adapters bind to the flow cell. By PCR the DNA is multiplied (PCR), and because of the adapters the multiplied DNA strand stays close to the original location. Then actual sequencing occurs, by adding fluorescently labeled nucleotides one at a time. explain how they work from start to beginning. As nucleotides are incorporated, the fluorescent signal is emitted and detected. The color of the signal corresponds to the type of nucleotide that was incorporated. This step provides the sequencing data for each position along the DNA fragment. During sequencing a camera films the process, where the order of the colors expressed at each spot (TODO use spot before) represents the DNA sequence.

\subsection{dry lab}

After sequencing, one ends up with video file tha (FASTQ) with for each DNA sequence there is a line in the file with the DNA sequence. One first needs to remove the sequencing adapters of these sequences, to then align these reads to the genome. Alignment to the genome is a compute-heavy task, as FASTQ files generally contain several millions of reads. After alignment one ends up with a map that aligns each read to a position in the genome. Generally the next step is to assign features to the genome based on where reads are positioned. For RNA-seq this is easy as we know where the genes are, and we can make a table with the number of reads found for each gene. For ATAC-seq and ChIP-seq experiments we generally do not know the regions of interest yet. So we 

\begin{figure}[H]
    \includegraphics[width=\linewidth]{ch.introduction/imgs/analysis.png}
    \caption{TODO}
    \label{fig:analysis}
\end{figure}

\subsection{Single cell}

Whereas originally 

\section{Evolutionary development (evo-devo)}

A single fertilized egg cell multiplies and develops into a complex collection of trillions of cells by the time we reach adulthood. How does each cell know where it is positioned in the body and what to develop into? The field of evolutionary development (evo-devo) studies development from an evolutionary point of view. In the 1980s scientists discovered a set of genes in fruit flies, which when mutated, are responsible for strange bodily transformations. A mutation in these genes causes flies to grow legs instead of antennae from their mouths\cite{Schneuwly1987}, or flies to develop a second pair of wings\cite{Weatherbee1998}. This work was revolutionary at its time as it showed that (precursor) antennae cells contain all the information necessary to build legs. The group of genes responsible for these mutations are transcription factors  known as Hox genes.

The embryonic development of a fruit fly starts as a worm-like larva consisting of multiple repeated segments. The gene expression of Hox genes determines each segment's identity and guides its growth. For example, the \textit{lab} hox-gene is expressed at the frontal part of the larva, indicating surrounding cells this area will develop into the mouth of the fly\cite{Hughes2002}. Similarly, the \textit{Antp} hox gene indicates leg formation and is expressed in the mid-section of the larva. Interestingly, Hox genes are found in nearly all animals, where they play an important role in the spatial organization of the organism. What makes Hox genes particularly fascinating is that their order on the chromosome is the same as the spatial ordering along embryos. This concept is called spatial colinearity, something we have no clear understanding of\cite{Gaunt2015}.

\begin{figure}[H]
    \center
    \includegraphics[width=0.5\linewidth]{ch.introduction/imgs/hox.png}
    \caption{caption}
    \label{fig:hox}
\end{figure}

Another remarkable family of transcription factors is the PAX transcription factors. While the HOX transcription factors are generally responsible for the anterior-posterior (head-to-tail) axis, the PAX transcription factors are involved in the development of structures like the eyes, ears, nervous system, and other organs. The most-studied of the family is the PAX6 transcription factor, which is involved in eye development and is highly conserved for bilateria (e.g. fruit flies, frogs, and humans). Injecting PAX6 into a developing frog embryo results in an extra eye on the spot of the injection\cite{Chow1999}.

The observation that single mutations can cause such large changes in body plans, in combination with the fact that the responsible genes are deeply conserved among species, shifted the way we think about evolution. Speciation does not have to happen through a combination of many small incremental mutations, but a few mutations, for instance, in the HOX or PAX genes, can cause major morphological changes. This is now the basis of the scientific field of evo-devo.

\subsection{The hourglass model and the phylotypic stage}

Where the molecular observations of the HOX and PAX genes are a relatively recent addition to the field of evo-devo, the oldest observations in the field are based on the morphology (shape) of embryos. Ernst Haeckel has done the most famous and influential observations in the field of evo-devo in the 1800s\cite{haeckel1866}. Through a series of observations and drawings of the embryonic development of different vertebrates, Haeckel noticed a stage early in development where all vertebrates appear morphologically similar. This stage is now known as the phylotypic stage (see figure \ref{fig:haeckel_wide}). The Origin of Species, \textit{the} book by Charles Darwin in which he proposes the evolution theory, was only published a decade before these observations, and the idea of a scala naturæ (the ordering of species into higher and lower species) was still prevalent at that time. Haeckel thought his observations could unify the scala naturæ and the evolution theory, and came with a refinement of the recapitulation theory. Haeckel proposed that embryos of higher species consecutively develop from embryos of lower species into embryos of higher species. For example, a human embryo, which would be the highest and most developed species, would first develop into a fish embryo, then a reptile embryo, and finally into a mammalian embryo. This would explain why, for instance, gills and tails develop in human embryos, to then later disappear. The recapitulation theory unifies the scala naturæ with evolution, as the higher species are more evolved than the lower ones. Haeckel was a strong proponent of eugenics and proposed an ordering in human races, where the Germanic race, coincidentally the race Haeckel belongs to, was listed all the way at the top\cite{Levit2020}. The recapitulation theory was already controversial at the time it was proposed and is refuted by the contemporary scientific community. Nevertheless, the notion of a morphologically conserved stage early in development is prevalent to this day.

\hvFloat[doublePage,capWidth=n,
capPos=bottom,bindCorr=0.0cm]{figure}
{\includegraphics[width=2.2\textwidth]
{ch.introduction/imgs/haeckel_wide.png}}
[accessibility schematic overview]
{George Romanes's 1892 copy of Ernst Haeckel's controversial embryo drawings}{fig:haeckel_wide}

In the same time period, Karl Ernst von Baer proposed an alternative theory of embryonic development. Von Baer was strongly opposed to Haeckel's recapitulation theory. He noted, for instance, that a yolk sac is present during bird embryonic development, but not for frog embryonic development. This is inconsistent with the recapitulation theory as frogs are considered a higher species than birds. Von Baer's opposing theory consisted of four main rules, or laws\cite{baer1828}. His first law states that \textit{the more general characters of a large group appear earlier in the embryo than the more special characters}. This means that as an embryo develops, it first develops its oldest phylum-specific features, to then respectively develop its class, order, family, and species-specific features. Simply put, embryos of related species become increasingly diverse as development proceeds. Von Baer did not believe in the idea of a single common ancestor for all life on earth, as he believed the differences between some species, e.g. humans and sponges, to be too large to be bridged by evolution.

Even though the theories of Von Baer and Haeckel are dismissed by contemporary biologists, their observations of a morphologically conserved stage in development remain intriguing and have led to the formulation of the hourglass model of development. The hourglass model is based on the model proposed by Paul Medawar in 1954\cite{Medawar1954}. Medawar argues that somewhere mid-embryogenesis is the most morphologically conserved stage for vertebrates. This stage corresponds to Haeckel's phylotypic stage, but, different from Haeckel's recapitulation theory, different species are thought to be more diverse both before and after the mid-embryogenesis state. As during the phylotypic stage the basic body plan is formed, it is a popular hypothesis that HOX genes are responsible for this conserved stage. And recently, molecular evidence has been generated that gene expression between different species is most similar at the phylotypic stage (TODO CITE THOSE PAPERS). This has led to the idea that the phylotypic stage is not just morphologically conserved, but also conserved on the level of gene expression and regulation. In chapter \textbf{TODO} I discuss the current statistical methods that estimate this molecular conservation, and by careful re-analysis, I demonstrate that the used methodology is biased. This in turn means that the conclusions the original authors draw about the phylotypic stage and the molecular hourglass model are unfounded. 

\section{Thesis overview}

This thesis focuses on the computational analysis of (evolutionary-) developmental processes. The current chapter (\textbf{chapter 1}) served as a general introduction to the scientific fields of computational genomics, gene regulation, and evolutionary development.  

In \textbf{chapter 2} I review the current computational approaches to model and understand gene regulatory networks in development. Current computational gene regulatory network inference methods perform poorly, and thus new approaches are needed. I highlight three recent developments for gene regulatory network inference which I expect to improve the power of these methods; multi-omics networks, single-cell data, and artificial neural networks. Multi-omics data partially solve the curse of dimensionality by constraining the problem and providing more data. Bulk sequencing measures the compound signal of multiple cell types. Single-cell sequencing, on the other hand, separates the signal per cell type, so cell-type-specific networks can be made and the data contains a purer signal. Artificial neural networks can model more complex gene-gene interactions than the current approaches. By combining these three approaches I expect future gene regulatory network inference methods to predict better networks.

In \textbf{chapter 3} I discuss the implementation of seq2science, a next-generation pre-processing workflow. Seq2science supports some of the most common assays, such as RNA-seq, ChIP-seq, and ATAC-seq, integrates with public databases, and reports an extensive quality control report. Seq2science has been tested on a wide array of different species and genome assemblies, and I show examples of common analyses that seq2science supports out of the box. Seq2science has an extensive user base\cite{Bright_2021,Xu_2020,Wester2021,SantosBarriopedro2021,Heuts2023,Tholen2023,Harlaar2022,LunaVelez2023,Neikes2023,Vierboom2021,Smits2020,Smits2022,Heuts2022,Rother2023}, is downloaded over 40K times through Bioconda, and has more than 120 ``stars'' on GitHub.

In \textbf{chapter 4} I discuss the implementation of Qnorm, a Python quantile normalization package. Quantile normalization is the process of fitting multiple distributions onto their average distribution. Python did not have a quantile normalization package yet, and the implementations on public fora about how to do quantile normalization did not resolve ties properly. Qnorm is fast-ish and scales to infinitely large tables as it can swap memory to disk.

In \textbf{chapter 5} I discuss the molecular basis of the phylotypic stage and its related models. I explain how the current definition and analyses of the phylotypic stage are ambiguous, as they do not distinguish within-species effects from between-species effects. For this reason, I propose that any study of the phylotypic stage includes at least a within-species comparison, a within-phylum comparison, and a between-phyla comparison. By applying these comparisons I find important flaws in the interpretation of previous results. I highlight three examples where the within-species pattern is enough to explain the between-species pattern. Moreover, I find that a supposed between-phyla effect, the mid-developmental transition, is a statistical artifact. Finally, I question the general validity of the current approaches to studying the phylotypic stage, as they are gross oversimplifications of the biological complexity during development.

In \textbf{chapter 6} 

Finally, in \textbf{chapter 7} I summarize and discuss the results described in this thesis, and give future perspectives on the field.
